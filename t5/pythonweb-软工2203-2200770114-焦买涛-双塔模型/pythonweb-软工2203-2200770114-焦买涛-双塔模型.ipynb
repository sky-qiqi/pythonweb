{
 "cells": [
  {
   "metadata": {},
   "cell_type": "raw",
   "source": "",
   "id": "65bce3e7ddc73130"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "** 作业5 **\n",
    "\n",
    "- 要求：\n",
    "\n",
    "1. 利用 TensorFlow Recommenders（TFRS）API 实现双塔模型\n",
    "\n",
    "\n",
    "2. 基于 MovieLens 数据集训练模型（对于电影，需要用除了 ID 以外的特征训练模型）\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ],
   "id": "344b237f8289eb72"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os\n",
    "import pprint\n",
    "import tempfile\n",
    "from typing import Dict, Text\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_recommenders as tfrs\n"
   ],
   "id": "1a8693e79a3c9f6c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "这些是导入的相关包。\n",
    "\n",
    "\n",
    "\n",
    "1. 数据加载与准备"
   ],
   "id": "dcef5997191faa86"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 加载 MovieLens 100k 数据集\n",
    "print(\"Loading dataset...\")\n",
    "# 在这里，我们保留 movie_genres 的原始整数格式\n",
    "ratings = tfds.load(\"movielens/100k-ratings\", split=\"train\")\n",
    "movies = tfds.load(\"movielens/100k-movies\", split=\"train\")\n",
    "\n",
    "# 提取用户ID和电影特征。注意这里 movie_genres 保持不变。\n",
    "ratings = ratings.map(lambda x: {\n",
    "    \"movie_title\": x[\"movie_title\"],\n",
    "    \"user_id\": x[\"user_id\"],\n",
    "    \"movie_genres\": x[\"movie_genres\"]\n",
    "})\n",
    "\n",
    "movies = movies.map(lambda x: {\n",
    "    \"movie_title\": x[\"movie_title\"],\n",
    "    \"movie_genres\": x[\"movie_genres\"]\n",
    "})\n",
    "\n",
    "# 构建用户ID和电影标题的词汇表 (它们是字符串/bytes)\n",
    "print(\"Building vocabularies for user_id and movie_title...\")\n",
    "user_ids_vocabulary = tf.keras.layers.StringLookup(mask_token=None)\n",
    "user_ids_vocabulary.adapt(ratings.map(lambda x: x[\"user_id\"]))\n",
    "\n",
    "movie_titles_vocabulary = tf.keras.layers.StringLookup(mask_token=None)\n",
    "movie_titles_vocabulary.adapt(movies.map(lambda x: x[\"movie_title\"]))\n",
    "\n",
    "# --- 找出电影类型的最大 ID ---\n",
    "# 因为 movie_genres 已经是整数 ID，我们需要找到最大的 ID 来设置 Embedding 层的大小\n",
    "print(\"Finding maximum movie genre ID...\")\n",
    "all_movie_genres_ids = []\n",
    "for movie in movies.map(lambda x: x[\"movie_genres\"]):\n",
    "    # movie[\"movie_genres\"] 是一个张量，可能包含多个 genre ID\n",
    "    # 在这里直接处理原始 movies 数据集，它里面的 movie_genres 仍然是标准的tf.Tensor\n",
    "    all_movie_genres_ids.extend(movie.numpy().tolist()) # 将张量转换为列表并添加到总列表\n",
    "\n",
    "max_movie_genre_id = max(all_movie_genres_ids)\n",
    "num_movie_genres = max_movie_genre_id + 1 # Embedding 层维度需要包含所有可能的 ID，从 0 到 max_id\n",
    "\n",
    "print(f\"Maximum movie genre ID found: {max_movie_genre_id}\")\n",
    "print(f\"Number of unique movie genres (for embedding layer): {num_movie_genres}\")\n",
    "\n",
    "\n",
    "# 数据划分\n",
    "print(\"Splitting data into train and test sets...\")\n",
    "tf.random.set_seed(42)\n",
    "shuffled_ratings = ratings.shuffle(100_000, seed=42, reshuffle_each_iteration=False)\n",
    "\n",
    "train = shuffled_ratings.take(80_000)\n",
    "test = shuffled_ratings.skip(80_000).take(20_000)\n",
    "\n",
    "# 批量处理和缓存数据\n",
    "print(\"Batching and caching data...\")\n",
    "# 修改：使用 ragged_batch 来处理训练/测试数据中 movie_genres 的可变长度\n",
    "cached_train = train.ragged_batch(4096).cache()\n",
    "cached_test = test.ragged_batch(4096).cache()"
   ],
   "id": "c418ad614d06dcb4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "2. 模型构建 (双塔模型)\n",
   "id": "784b0a571b1a28f2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "embedding_dimension = 64  # 嵌入维度，可以调整\n",
    "\n",
    "# 定义用户模型 (Query tower)\n",
    "user_model = tf.keras.Sequential([\n",
    "    user_ids_vocabulary,\n",
    "    # 修正：使用 vocabulary_size()\n",
    "    tf.keras.layers.Embedding(user_ids_vocabulary.vocabulary_size(), embedding_dimension)\n",
    "])\n",
    "\n",
    "# 定义电影模型 (Candidate tower)\n",
    "class MovieCandidateModel(tf.keras.Model):\n",
    "    def __init__(self, movie_titles_vocabulary, num_movie_genres, embedding_dimension):\n",
    "        super().__init__()\n",
    "        # 处理电影标题 (字符串 -> 嵌入)\n",
    "        self.movie_titles_embedding = tf.keras.Sequential([\n",
    "            movie_titles_vocabulary,\n",
    "            # 修正：使用 vocabulary_size()\n",
    "            tf.keras.layers.Embedding(movie_titles_vocabulary.vocabulary_size(), embedding_dimension)\n",
    "        ])\n",
    "        # 处理电影类型 (整数 ID -> 嵌入)\n",
    "        # Embedding 层能够处理 RaggedTensor 输入\n",
    "        self.movie_genres_embedding = tf.keras.layers.Embedding(\n",
    "            input_dim=num_movie_genres,\n",
    "            output_dim=embedding_dimension\n",
    "        )\n",
    "        # 组合不同特征的 embeddings\n",
    "        self.combination_layer = tf.keras.layers.Dense(embedding_dimension, activation=\"relu\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # inputs[\"movie_title\"] 是一个 Tensor 或 RaggedTensor (来自 ragged_batch)\n",
    "        # inputs[\"movie_genres\"] 是一个 RaggedTensor (来自 ragged_batch)\n",
    "        title_embedding = self.movie_titles_embedding(inputs[\"movie_title\"])\n",
    "        genres_embedding = self.movie_genres_embedding(inputs[\"movie_genres\"]) # Output is RaggedTensor\n",
    "\n",
    "        # 对 RaggedTensor 进行求和，axis=1 会在每个样本内部的第二个维度（嵌入维度）求和\n",
    "        # 结果 shape 是 [batch_size, embedding_dimension]\n",
    "        genres_embedding_aggregated = tf.reduce_sum(genres_embedding, axis=1)\n",
    "\n",
    "        # 确保 title_embedding 是密集张量以便拼接\n",
    "        # 理论上 movie_title 应该是密集张量，但为了保险，这里检查并转换\n",
    "        if isinstance(title_embedding, tf.RaggedTensor):\n",
    "            title_embedding = title_embedding.to_tensor()\n",
    "\n",
    "\n",
    "        combined_embedding = tf.concat([title_embedding, genres_embedding_aggregated], axis=1)\n",
    "        return self.combination_layer(combined_embedding)\n",
    "\n",
    "\n",
    "# 定义完整的 TFRS 模型\n",
    "class MovieLensModel(tfrs.Model):\n",
    "    def __init__(self, user_model, movie_model, movies_dataset):\n",
    "        super().__init__()\n",
    "        self.user_model = user_model\n",
    "        self.movie_model = movie_model\n",
    "        # 定义检索任务和评估指标\n",
    "        # 注意：这里的 candidates 应该是经过 movie_model 处理后的电影 embeddings\n",
    "        # 这里需要将 movies_dataset 的每个元素（字典）传递给 movie_model\n",
    "        self.task = tfrs.tasks.Retrieval(\n",
    "            metrics=tfrs.metrics.FactorizedTopK(\n",
    "                # 修改：对用于 candidates 的数据集也使用 ragged_batch\n",
    "                candidates=movies_dataset.ragged_batch(128).map(self.movie_model)\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n",
    "        # features[\"user_id\"] 是一个 Tensor (通常来自原始数据集或 map)\n",
    "        # features[\"movie_title\"] 是一个 Tensor 或 RaggedTensor (来自 ragged_batch)\n",
    "        # features[\"movie_genres\"] 是一个 RaggedTensor (来自 ragged_batch)\n",
    "\n",
    "        # 计算用户和电影的 embeddings\n",
    "        user_embeddings = self.user_model(features[\"user_id\"])\n",
    "        # 将完整的电影特征字典传递给 movie_model\n",
    "        movie_embeddings = self.movie_model({\n",
    "            \"movie_title\": features[\"movie_title\"],\n",
    "            \"movie_genres\": features[\"movie_genres\"]\n",
    "        })\n",
    "\n",
    "        # 将 embeddings 传递给任务计算损失\n",
    "        return self.task(user_embeddings, movie_embeddings)\n",
    "\n",
    "# 创建电影候选模型实例\n",
    "movie_candidate_model = MovieCandidateModel(movie_titles_vocabulary, num_movie_genres, embedding_dimension)\n",
    "\n",
    "# 创建完整的 TFRS 模型实例\n",
    "# 注意：这里的 movies 数据集需要保留 movie_genres 特征以便传递给 movie_model\n",
    "model = MovieLensModel(user_model, movie_candidate_model, movies)\n"
   ],
   "id": "dd597d93bb49bc89"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "3. 模型编译与训练",
   "id": "6fbae920655bbe6d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "\n",
    "\n",
    "print(\"Compiling and training the model...\")\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(0.5))\n",
    "\n",
    "# 训练模型\n",
    "model.fit(cached_train, epochs=3) # 可以调整训练轮数\n",
    "\n"
   ],
   "id": "b5855e4b43f5b57b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "4. 模型评估\n",
    "\n"
   ],
   "id": "36c3b98553a4ec7c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print(\"Evaluating the model...\")\n",
    "model.evaluate(cached_test, return_dict=True)\n"
   ],
   "id": "2306dd950ec81d4d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "5. 生成推荐",
   "id": "2974c679a99cc93a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "print(\"Generating recommendations...\")\n",
    "# 构建检索索引。索引是基于电影 embeddings 构建的。\n",
    "# 注意：这里需要使用 movie_candidate_model 来处理电影数据以获取 embeddings\n",
    "index = tfrs.layers.factorized_top_k.BruteForce(model.user_model)\n",
    "# 在 index_from_dataset 中，需要传递电影的特征字典给 movie_model\n",
    "# 修改：对用于构建索引的 movies 数据集也使用 ragged_batch\n",
    "index.index_from_dataset(\n",
    "    movies.ragged_batch(100).map(lambda movie_features: (\n",
    "        movie_features[\"movie_title\"], # 使用电影标题作为标识符\n",
    "        model.movie_model(movie_features) # 将电影特征字典传递给 movie_model\n",
    "    ))\n",
    ")\n",
    "\n",
    "# 为特定用户生成 Top-K 推荐\n",
    "user_id_to_recommend = \"33\"\n",
    "# 获取用户 embedding\n",
    "# user_embedding = model.user_model(tf.constant([user_id_to_recommend])) # 这行不再需要了\n",
    "\n",
    "# 使用索引查找最相似的电影\n",
    "# index 返回两个张量：第一个是相似度得分，第二个是电影标题（或其他你用于索引的标识符）\n",
    "# 修改：直接将原始用户 ID 张量传递给 index 层，它会内部调用 user_model\n",
    "scores, titles = index(tf.constant([user_id_to_recommend])) # 修改为这行\n",
    "\n",
    "print(f\"Top recommendations for user {user_id_to_recommend}:\")\n",
    "# 解码 byte string 并打印电影标题\n",
    "for title in titles[0, :10].numpy():\n",
    "    print(title.decode(\"utf-8\"))"
   ],
   "id": "d331f7e2a540d168"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "总体解释\n",
    "\n",
    "数据加载与准备: 从 tensorflow_datasets 中加载 MovieLens 100k 数据集，提取出用户ID、电影标题和电影类型等特征。对用户ID和电影标题构建词汇表，并找出电影类型ID的最大值以确定 Embedding 层的维度。将数据划分为训练集和测试集，并使用 ragged_batch 进行批量处理和缓存，以处理电影类型列表的可变长度。\n",
    "\n",
    "模型构建: 定义了两个独立的神经网络模型：用户模型（Query tower）和电影模型（Candidate tower）。用户模型将用户ID嵌入到低维向量空间。电影模型将电影标题（通过词汇表和 Embedding）和电影类型（通过 Embedding 并求和）组合起来，嵌入到低维向量空间。然后，定义了一个完整的 TFRS MovieLensModel，它结合了用户模型和电影模型，并使用 tfrs.tasks.Retrieval 定义了召回任务和 FactorizedTopK 评估指标。\n",
    "\n",
    "模型编译与训练: 使用 Adagrad 优化器编译模型，然后在处理好的训练数据集上进行训练。\n",
    "\n",
    "模型评估: 在处理好的测试数据集上评估模型的性能，使用 FactorizedTopK 指标来衡量召回的准确性。\n",
    "\n",
    "生成推荐: 构建一个基于电影 embeddings 的检索索引 (BruteForce)。然后，为特定用户（例如用户ID \"42\" 或 \"33\"）计算其 embedding，并使用索引查找与其 embedding 最相似的 Top-K 部电影，最后输出推荐的电影标题。\n",
    "\n",
    "简而言之，代码的核心思想是将用户和电影都表示成低维度的向量（embeddings），并通过训练使得用户 embedding 与用户喜欢（评分高）的电影 embedding 在向量空间中距离更近。在推荐时，只需找到用户 embedding 最接近的电影 embeddings 对应的电影。\n",
    "\n",
    "\n",
    "\n",
    "运行结果\n",
    "\n",
    "\n"
   ],
   "id": "fa5cd2056598ec1a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "D:\\devenvironment\\Anaconda\\anacondadata\\envs\\py310\\python.exe C:\\Users\\qiqi\\OneDrive\\Desktop\\code\\pythonweb\\t5\\untitled\\1.py\n",
    "2025-05-09 18:51:25.218567: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
    "WARNING:tensorflow:From D:\\devenvironment\\Anaconda\\anacondadata\\envs\\py310\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
    "\n",
    "Loading dataset...\n",
    "2025-05-09 18:51:30.361062: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
    "To enable the following instructions: SSE SSE2 SSE3 SSE4.1 SSE4.2 AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
    "Building vocabularies for user_id and movie_title...\n",
    "WARNING:tensorflow:From D:\\devenvironment\\Anaconda\\anacondadata\\envs\\py310\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
    "\n",
    "WARNING:tensorflow:From D:\\devenvironment\\Anaconda\\anacondadata\\envs\\py310\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
    "\n",
    "WARNING:tensorflow:From D:\\devenvironment\\Anaconda\\anacondadata\\envs\\py310\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
    "\n",
    "WARNING:tensorflow:From D:\\devenvironment\\Anaconda\\anacondadata\\envs\\py310\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
    "\n",
    "Finding maximum movie genre ID...\n",
    "Maximum movie genre ID found: 19\n",
    "Number of unique movie genres (for embedding layer): 20\n",
    "Splitting data into train and test sets...\n",
    "                                   Batching and caching data...\n",
    "                                                        Compiling and training the model...\n",
    "Epoch 1/3\n",
    "20/20 [==============================] - 6s 228ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0281 - factorized_top_k/top_5_categorical_accuracy: 0.1985 - factorized_top_k/top_10_categorical_accuracy: 0.4076 - factorized_top_k/top_50_categorical_accuracy: 0.7261 - factorized_top_k/top_100_categorical_accuracy: 0.7475 - loss: 59228.3921 - regularization_loss: 0.0000e+00 - total_loss: 59228.3921\n",
    "Epoch 2/3\n",
    "20/20 [==============================] - 4s 216ms/step - factorized_top_k/top_1_categorical_accuracy: 0.2129 - factorized_top_k/top_5_categorical_accuracy: 0.9353 - factorized_top_k/top_10_categorical_accuracy: 0.9996 - factorized_top_k/top_50_categorical_accuracy: 0.9996 - factorized_top_k/top_100_categorical_accuracy: 0.9996 - loss: 32417.6583 - regularization_loss: 0.0000e+00 - total_loss: 32417.6583\n",
    "Epoch 3/3\n",
    "20/20 [==============================] - 4s 216ms/step - factorized_top_k/top_1_categorical_accuracy: 0.3454 - factorized_top_k/top_5_categorical_accuracy: 0.9998 - factorized_top_k/top_10_categorical_accuracy: 0.9998 - factorized_top_k/top_50_categorical_accuracy: 0.9998 - factorized_top_k/top_100_categorical_accuracy: 0.9998 - loss: 32417.5084 - regularization_loss: 0.0000e+00 - total_loss: 32417.5084\n",
    "Evaluating the model...\n",
    "5/5 [==============================] - 2s 195ms/step - factorized_top_k/top_1_categorical_accuracy: 0.3415 - factorized_top_k/top_5_categorical_accuracy: 0.9995 - factorized_top_k/top_10_categorical_accuracy: 0.9995 - factorized_top_k/top_50_categorical_accuracy: 0.9995 - factorized_top_k/top_100_categorical_accuracy: 0.9995 - loss: 32588.9043 - regularization_loss: 0.0000e+00 - total_loss: 32588.9043\n",
    "Generating recommendations...\n",
    "Top recommendations for user 33:\n",
    "    Children of the Corn: The Gathering (1996)\n",
    "You So Crazy (1994)\n",
    "Love Is All There Is (1996)\n",
    "Fly Away Home (1996)\n",
    "In the Line of Duty 2 (1987)\n",
    "Niagara, Niagara (1997)\n",
    "Young Poisoner's Handbook, The (1995)\n",
    "Age of Innocence, The (1993)\n",
    "Flirt (1995)\n",
    "Frisk (1995)\n",
    "\n",
    "进程已结束，退出代码为 0\n"
   ],
   "id": "a609f8f73937b724"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "运行结果分析：\n",
    "\n",
    "数据加载与准备: 脚本成功加载了 MovieLens 100k 数据集，构建了用户ID和电影标题的词汇表，确定了电影类型的数量，并将数据正确地划分并使用 ragged_batch 进行了批量处理和缓存。这些步骤都没有出现错误。\n",
    "\n",
    "模型训练: 模型在训练集上进行了 3 个 epoch 的训练。从输出的指标可以看到：\n",
    "\n",
    "loss（总损失）在每个 epoch 结束时逐渐下降，表明模型正在学习。\n",
    "factorized_top_k/top_1_categorical_accuracy（Top-1 准确率）在训练过程中有所提升，从第一轮的约 0.0281 提高到第三轮的约 0.3454。这意味着在训练集上，模型预测得分最高的电影是用户实际交互过的电影的比例有所增加。\n",
    "top_5、top_10、top_50 和 top_100 的准确率在训练后期迅速接近 1.0000。这表明虽然模型不一定总能将用户实际交互过的电影排在第一位，但它很有可能将这些电影排在预测结果的前几名或前几十名中。\n",
    "模型评估: 脚本在测试集上对训练好的模型进行了评估。\n",
    "\n",
    "factorized_top_k/top_1_categorical_accuracy 在测试集上约为 0.3415，与训练集上的最终结果接近。这表明模型具有一定的泛化能力，在未见过的数据上也能保持类似的 Top-1 性能。\n",
    "同样，测试集上的其他 Top-K 准确率（Top-5 到 Top-100）也非常高，接近 1.0000。这再次强调了模型能够有效地将用户可能感兴趣的电影包含在 Top-K 的推荐列表中。\n",
    "生成推荐: 脚本成功地为用户 33 生成了 Top-10 推荐电影列表，并打印出了电影标题。这验证了构建的检索索引和推荐流程是正常工作的。\n",
    "\n",
    "总结:\n",
    "\n",
    "总体而言，运行结果显示你已经成功地使用 TFRS 库构建并训练了一个基本的双塔召回模型，并且能够用它来为用户生成推荐。训练和评估指标看起来合理，特别是较高的 Top-K 准确率符合召回模型的特点（旨在从大量候选集中召回用户可能感兴趣的一小部分）。"
   ],
   "id": "fe7df6528ea9b60b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
